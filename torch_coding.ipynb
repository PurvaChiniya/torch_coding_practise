{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ab7d82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:\n",
      " tensor([[0],\n",
      "        [1],\n",
      "        [2]])\n",
      "y:\n",
      " tensor([[0, 1]])\n",
      "Broadcasted add:\n",
      " tensor([[0, 1],\n",
      "        [1, 2],\n",
      "        [2, 3]])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "x = torch.arange(3).reshape(3,1)\n",
    "y = torch.arange(2).reshape(1,2)\n",
    "print(\"x:\\n\", x)\n",
    "print(\"y:\\n\", y)\n",
    "print(\"Broadcasted add:\\n\", x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b767f064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask:\n",
      " tensor([[False, False,  True],\n",
      "        [ True,  True,  True]])\n",
      "Filtered: tensor([3, 4, 5, 6])\n",
      "Fancy index: tensor([3, 5])\n"
     ]
    }
   ],
   "source": [
    "# masking \n",
    "t = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "mask = t > 2\n",
    "filtered = t[mask]\n",
    "print(\"Mask:\\n\", mask)\n",
    "print(\"Filtered:\", t[mask])\n",
    "rows = torch.tensor([0, 1])\n",
    "cols = torch.tensor([2, 1])\n",
    "print(\"Fancy index:\", t[rows, cols])\n",
    "\n",
    "# When you do t[rows, cols], PyTorch zips up both tensors:\n",
    "# If rows and cols have the same shape, each pair defines one coordinate to grab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e0951e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "Sum: tensor(12.)\n",
      "torch.Size([3, 4])\n",
      "Mean over rows: tensor([4., 4., 4.])\n",
      "Mean over cols : tensor([3., 3., 3., 3.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(3, 4)\n",
    "print(x)\n",
    "print(\"Sum:\", x.sum())\n",
    "print(x.shape)\n",
    "print(\"Mean over rows:\", x.sum(dim=1))\n",
    "print(\"Mean over cols :\", x.sum(dim=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c76cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2, 4])\n",
      "torch.Size([2, 2, 3, 4])\n",
      "torch.Size([2, 3, 8])\n"
     ]
    }
   ],
   "source": [
    "a = torch.arange(24).reshape(2,3,4)\n",
    "p = a.permute(1,0,2)\n",
    "print(p.shape)\n",
    "b = torch.ones_like(a) # shape of b  3 2 4 \n",
    "stacked = torch.stack([a, b], dim=0) # 2 2 3 4 \n",
    "print(stacked.shape) \n",
    "concat = torch.cat([a, b], dim=2)\n",
    "print(concat.shape) # 2 3 8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4bba85d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10, 4])\n",
      "torch.Size([5, 10, 4])\n",
      "5\n",
      "torch.Size([10, 4])\n",
      "torch.Size([10, 20])\n"
     ]
    }
   ],
   "source": [
    "# Split a tensor of shape (10, 20) into five equal chunks along dim=1, then recombine them using torch.cat().\n",
    "a = torch.randn(10, 20)\n",
    "x = a.reshape(5,-1, 4 )\n",
    "print(x.shape)\n",
    "# combine usign cat \n",
    "y = torch.cat([x], dim = 0 )\n",
    "print(y.shape)\n",
    "# use torch.chunk instead \n",
    "chunks = torch.chunk(a, 5, dim=1)\n",
    "print(len(chunks))        # 5 chunks\n",
    "print(chunks[0].shape)\n",
    "y = torch.cat(chunks, dim = -1)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b20fba38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "A = torch.randn(3, 4)\n",
    "B = torch.randn(4, 2)\n",
    "C = torch.einsum('ik,kj->ij', A, B)\n",
    "print(C.shape)  # (3,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "144b74bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n",
      "tensor([[ 1.0403, -0.8417,  0.4006],\n",
      "        [-0.7540,  0.6100, -0.2904],\n",
      "        [-0.7912,  0.6401, -0.3047]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(3)\n",
    "b = torch.randn(3)\n",
    "print(a.shape)\n",
    "y = torch.einsum(\"i,j->ij\", a, b)\n",
    "print(y)\n",
    "# batch matrix multiplication torch.einsum(\"bij,bjk->bik\", a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "81ae9824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2, 4])\n",
      "False\n",
      "torch.Size([6, 4])\n",
      "True\n",
      "torch.Size([4, 3, 2])\n",
      "False\n",
      "torch.Size([4, 3, 2])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(24).reshape(2, 3, 4)\n",
    "y = x.permute(1, 0, 2)      # change axis order\n",
    "print(y.shape) # 3, 2,4 \n",
    "print(y.is_contiguous())    # often False\n",
    "z = y.contiguous().view(-1, 4) # 3, 2,4 view changes to 6, 4 \n",
    "print(z.shape)\n",
    "\n",
    "\n",
    "# ques2 \n",
    "x = torch.randn(2, 3,4 )\n",
    "print(x.is_contiguous())\n",
    "y = x.permute(2,1,0  ) # .permute often needs contiguous \n",
    "print(y.shape)\n",
    "print(y.is_contiguous())\n",
    "z = x.reshape(4, 3, 2 )\n",
    "print(z.shape)\n",
    "print(z.is_contiguous())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8d770349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 2])\n",
      "torch.Size([10, 32, 64])\n"
     ]
    }
   ],
   "source": [
    "A = torch.randn(5, 3, 4)\n",
    "B = torch.randn(5, 4, 2)\n",
    "C = torch.bmm(A, B)\n",
    "print(C.shape) # 5 3 2 \n",
    "A = torch.randn(10, 32, 100)\n",
    "B = torch.randn(10, 100, 64)\n",
    "C = torch.matmul(A, B, )\n",
    "print(C.shape)\n",
    "#. torch.bmm → when you’re multiplying clean batches inside a model (e.g., attention heads).\n",
    "#torch.matmul → when your shapes might vary or need broadcasting flexibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ea7d0f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4])\n",
      "tensor([[1, 1, 1, 1],\n",
      "        [2, 2, 2, 2],\n",
      "        [3, 3, 3, 3]])\n",
      "torch.Size([9, 4])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1], [2], [3]]) # shap 3 , 1\n",
    "\n",
    "y = x.expand(3,4)\n",
    "print(y.shape)\n",
    "print(y)\n",
    "z =  x.repeat(3,4)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dd994460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11, 12, 13],\n",
      "        [24, 25, 26]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1,2,3],\n",
    "                  [4,5,6]])\n",
    "b = torch.tensor([[10],\n",
    "                  [20]])\n",
    "print(a+b) # 10 12 13, 25, 25, 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ad649445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 1],\n",
       "         [2, 3]],\n",
       "\n",
       "        [[4, 5],\n",
       "         [6, 7]]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(8).reshape(2, 2, 2)\n",
    "y = x.permute(2, 0, 1)\n",
    "print(y.shape)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "aaf4651d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 5])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(3, 1, 5)\n",
    "b = torch.randn(1, 4, 1)\n",
    "c = a + b\n",
    "c.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "efbdc854",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.allclose(c[0, :, 0 ] ,  b[0, :, 0 ]+ a [0, 0 ,0 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5f21f25f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1],\n",
       "        [2, 2, 2, 2],\n",
       "        [3, 3, 3, 3]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch repeat vs expand\n",
    "x = torch.tensor([[1], [2], [3]])      # (3,1)\n",
    "y = x.expand(3, 4)\n",
    "z = x.repeat(1, 4)\n",
    "z\n",
    "# .expand() just views the same data in memory, pretending the tensor grew by using stride tricks (no copy).\n",
    "#.repeat() actually copies data, creating a fresh chunk of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5abcc37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1],\n",
       "        [2, 2, 2, 2],\n",
       "        [3, 3, 3, 3]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a85b0f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12.)\n"
     ]
    }
   ],
   "source": [
    "class WeirdSquare(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        # save tensor for backward\n",
    "        ctx.save_for_backward(input)\n",
    "        return input**2\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        # compute custom grad\n",
    "        x, = ctx.saved_tensors\n",
    "\n",
    "        return 4*x\n",
    "x = torch.tensor(3.0, requires_grad=True)\n",
    "y = WeirdSquare.apply(x)\n",
    "y.backward()\n",
    "print(x.grad)  # should be 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc809b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmoothL1Beta(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, y_hat, y, beta):\n",
    "        beta_clamped = beta.clamp_min(1e-6)\n",
    "        r = y_hat - y\n",
    "        mask = (r.abs() < beta_clamped)\n",
    "        ctx.save_for_backward(r, beta_clamped, mask)\n",
    "        loss = torch.where(mask,\n",
    "                           0.5 * r**2 / beta_clamped,\n",
    "                           r.abs() - 0.5 * beta_clamped)\n",
    "        return loss.sum()\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        r, beta_clamped, mask = ctx.saved_tensors\n",
    "\n",
    "        # ∂L/∂r (which is also ∂L/∂y_hat)\n",
    "        grad_r = torch.where(mask, r / beta_clamped, r.sign())\n",
    "\n",
    "        # ∂L/∂β\n",
    "        grad_beta = torch.where(mask,\n",
    "                                -0.5 * r**2 / (beta_clamped**2),\n",
    "                                -0.5 * torch.ones_like(beta_clamped))\n",
    "\n",
    "        grad_yhat = grad_output * grad_r\n",
    "        grad_y = -grad_yhat   # because L depends on (y_hat - y)\n",
    "        grad_beta = grad_output * grad_beta\n",
    "\n",
    "        return grad_yhat, grad_y, grad_beta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "10949619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stable_logsumexp(x, dim = 1):\n",
    "    x_max = x.max(dim=dim, keepdim=True).values\n",
    "    return x_max+ torch.log(torch.sum(torch.exp(x - x_max), dim=dim, keepdim=True))\n",
    "    # pull xmax outside \n",
    "x = (torch.randn(4, 7) * 10).requires_grad_() \n",
    "y = stable_logsumexp(x, dim=1).sum()\n",
    "y.backward()\n",
    "assert torch.allclose(x.grad, torch.softmax(x, dim=1), atol=1e-5, rtol=1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9186813f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LayerNorm backward check (spot the bug)\n",
    "mu = x.mean(dim=-1, keepdim=True)\n",
    "var = ((x - mu)**2).mean(dim=-1, keepdim=True)\n",
    "y = (x - mu) / torch.sqrt(var + 1e-5)\n",
    "out = y * gamma + beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a3a0ffa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- normal forward ----\n",
      "  running forward fn()\n",
      "  backward done\n",
      "\n",
      "---- checkpointed forward ----\n",
      "  running forward fn()\n",
      "  running forward fn()\n",
      "  backward done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# gradient vs activation checkpoinintg \n",
    "\n",
    "import torch\n",
    "# Activation Checkpointing\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "\n",
    "# Example function that logs what it's doing\n",
    "def fn(x):\n",
    "    print(\"  running forward fn()\")\n",
    "    return x ** 2\n",
    "\n",
    "x = torch.tensor(3.0, requires_grad=True)\n",
    "\n",
    "print(\"---- normal forward ----\")\n",
    "y1 = fn(x)\n",
    "y1.backward()\n",
    "print(\"  backward done\\n\")\n",
    "\n",
    "x = torch.tensor(3.0, requires_grad=True)\n",
    "print(\"---- checkpointed forward ----\")\n",
    "y2 = checkpoint(fn, x)\n",
    "y2.backward()\n",
    "print(\"  backward done\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088b8d18",
   "metadata": {},
   "source": [
    "Gradient Checkpointing (the broader umbrella term)\n",
    "\n",
    "Technically, activation checkpointing is a specific kind of gradient checkpointing.\n",
    "“Gradient checkpointing” means any strategy that saves only a subset of activations (“checkpoints”) and recomputes everything else on backward to reduce memory load.\n",
    "\n",
    "So:\n",
    "\n",
    "“Activation checkpointing” → PyTorch’s implementation: store only segment boundaries, recompute insides.\n",
    "\n",
    "“Gradient checkpointing” → general term covering that plus fancier graph-level algorithms like:\n",
    "\n",
    "Rematerialization (used in JAX, DeepSpeed)\n",
    "\n",
    "Gradient-remap checkpointing (saves intermediate grads instead of activations)\n",
    "\n",
    "Selective gradient offload (move grads/acts to CPU or NVMe, not recompute them)\n",
    "\n",
    "ZeRO-Offload / DeepSpeed Stage-3 (shard or offload gradients, parameters, optimizer states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d72892",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16390c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "## mixed precision logic \n",
    "# scaler = torch.cuda.amp.GradScaler()\n",
    "# for inputs, labels in dataloader:\n",
    "#     optimizer.zero_grad()\n",
    "#     with torch.cuda.amp.autocast():\n",
    "#         outputs = model(inputs)\n",
    "#         loss = loss_fn(outputs, labels)\n",
    "#     scaler.scale(loss).backward()\n",
    "#     scaler.step(optimizer)\n",
    "#     scaler.update()\n",
    "# It automatically runs each operation in the cheapest safe precision:\n",
    "\n",
    "# FP16/BF16 for matmuls, convolutions, attention blocks — anything with big, well-behaved values.\n",
    "\n",
    "# FP32 for operations prone to numerical instability — e.g., softmax, normalization, variance, loss functions.\n",
    "# PyTorch tracks this automatically via op-specific “whitelists” and “blacklists.”\n",
    "\n",
    "\n",
    "# 2. scaler.scale() / scaler.step()\n",
    "\n",
    "# scaler.scale(loss) multiplies the loss by a dynamic scaling factor before backward, magnifying small gradients so they don’t underflow to zero in FP16.\n",
    "\n",
    "# The backward pass computes scaled gradients in FP16/FP32 mix.\n",
    "\n",
    "# scaler.step(optimizer) first unscales those gradients (divides by the same scale), checks for NaNs/Infs, and only updates weights if they’re finite.\n",
    "\n",
    "# scaler.update() adjusts the scale up or down depending on whether gradients overflowed.\n",
    "#so we scale up the loss, compute gradient, scale down by the smae scale , check for inf or Nans and then update, adjust the scale usign scale.update() if needed\n",
    "\n",
    "\n",
    "# 3. Why this matters\n",
    "# FP16 has only ~10 bits of mantissa → values smaller than ~1e-7 vanish (underflow).\n",
    "# Without scaling, gradients can become all zeros or NaN.\n",
    "# AMP keeps most compute in FP16 for speed and memory efficiency, but protects numerically sensitive ops and gradients in FP32 for precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8c9f4f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor A (shape torch.Size([3, 4])):\n",
      "tensor([[ 1.,  2.,  3.,  4.],\n",
      "        [ 5.,  6.,  7.,  8.],\n",
      "        [ 9., 10., 11., 12.]])\n",
      "\n",
      "Tensor B (shape torch.Size([2, 1, 3, 3])):\n",
      "tensor([[[[ 0.,  1.,  2.],\n",
      "          [ 3.,  4.,  5.],\n",
      "          [ 6.,  7.,  8.]]],\n",
      "\n",
      "\n",
      "        [[[ 9., 10., 11.],\n",
      "          [12., 13., 14.],\n",
      "          [15., 16., 17.]]]])\n",
      "\n",
      "Tensor C (shape torch.Size([3])):\n",
      "tensor([10, 20, 30])\n",
      "\n",
      "Tensor D (shape torch.Size([4, 5])):\n",
      "tensor([[-0.5172, -1.1899, -0.3756,  0.0917,  2.8955],\n",
      "        [-0.9880,  0.0651,  0.7884,  0.3716,  0.2358],\n",
      "        [ 0.9267,  1.2892, -0.8128,  1.4235,  0.8271],\n",
      "        [ 1.7586,  1.6394,  0.7147, -1.2115, -0.7852]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# --- Tensors for Your Practice ---\n",
    "\n",
    "# A 2D tensor (a matrix)\n",
    "tensor_a = torch.tensor([[1, 2, 3, 4],\n",
    "                         [5, 6, 7, 8],\n",
    "                         [9, 10, 11, 12]], dtype=torch.float32)\n",
    "\n",
    "# A 3D tensor representing a small batch of 2 images, each with 1 channel and 3x3 pixels\n",
    "tensor_b = torch.arange(18, dtype=torch.float32).reshape(2, 1, 3, 3)\n",
    "\n",
    "# A 1D tensor (a vector)\n",
    "tensor_c = torch.tensor([10, 20, 30])\n",
    "\n",
    "# A tensor with random values for matrix multiplication practice\n",
    "tensor_d = torch.randn(4, 5)\n",
    "\n",
    "\n",
    "# --- Print tensors to see what you're working with ---\n",
    "print(\"Tensor A (shape {}):\\n{}\".format(tensor_a.shape, tensor_a))\n",
    "print(\"\\nTensor B (shape {}):\\n{}\".format(tensor_b.shape, tensor_b))\n",
    "print(\"\\nTensor C (shape {}):\\n{}\".format(tensor_c.shape, tensor_c))\n",
    "print(\"\\nTensor D (shape {}):\\n{}\".format(tensor_d.shape, tensor_d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "5820f9dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.,  4.],\n",
       "        [ 5.,  6.,  7.,  8.],\n",
       "        [ 9., 10., 11., 12.]])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4068a7e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.,  2.],\n",
       "          [ 3.,  4.,  5.],\n",
       "          [ 6.,  7.,  8.]]],\n",
       "\n",
       "\n",
       "        [[[ 9., 10., 11.],\n",
       "          [12., 13., 14.],\n",
       "          [15., 16., 17.]]]])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "edd120b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_b  = torch.max(tensor_b)\n",
    "tensor_b = tensor_b/ max_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "8a32dae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "# --- Tensors for Advanced Practice ---\n",
    "\n",
    "# A batch of logits (raw outputs from a model)\n",
    "# Shape: (batch_size, num_classes)\n",
    "logits = torch.tensor([[2.0, 1.0, 0.1],\n",
    "                       [-0.5, 1.5, 2.5]], dtype=torch.float32)\n",
    "\n",
    "# A batch of integer class labels for one-hot encoding\n",
    "# Shape: (batch_size,)\n",
    "labels = torch.tensor([0, 2])\n",
    "\n",
    "# Tensors for a simplified self-attention mechanism\n",
    "# Shape: (batch_size, sequence_length, embedding_dim)\n",
    "query = torch.randn(2, 4, 8) # 2 batches of 4 tokens, each with an 8-dim embedding\n",
    "key = torch.randn(2, 4, 8)\n",
    "value = torch.randn(2, 4, 8)\n",
    "\n",
    "# A target tensor for the gradient problem\n",
    "target = torch.tensor([1.0, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "c426b4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    z = torch.exp(z)\n",
    "    return z/ torch.sum(z, dim = 1 , keepdim= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "04223b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6590, 0.2424, 0.0986],\n",
       "        [0.0351, 0.2595, 0.7054]])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "f81da863",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "scatter_() received an invalid combination of arguments - got (src=int, index=Tensor, dim=int, ), but expected one of:\n * (int dim, Tensor index, Tensor src)\n      didn't match because some of the arguments have invalid types: (dim=int, index=Tensor, !src=int!, )\n * (int dim, Tensor index, Tensor src, *, str reduce)\n * (int dim, Tensor index, Number value)\n      didn't match because some of the keywords were incorrect: src\n * (int dim, Tensor index, Number value, *, str reduce)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[204]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m labels = labels.unsqueeze(\u001b[32m1\u001b[39m)\n\u001b[32m      3\u001b[39m one_hot = torch.zeros_like(logits) \u001b[38;5;66;03m# batch x classes \u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mone_hot\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscatter_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: scatter_() received an invalid combination of arguments - got (src=int, index=Tensor, dim=int, ), but expected one of:\n * (int dim, Tensor index, Tensor src)\n      didn't match because some of the arguments have invalid types: (dim=int, index=Tensor, !src=int!, )\n * (int dim, Tensor index, Tensor src, *, str reduce)\n * (int dim, Tensor index, Number value)\n      didn't match because some of the keywords were incorrect: src\n * (int dim, Tensor index, Number value, *, str reduce)\n"
     ]
    }
   ],
   "source": [
    "n_classes = logits.shape[1]\n",
    "labels = labels.unsqueeze(1)\n",
    "one_hot = torch.zeros_like(logits) # batch x classes \n",
    "one_hot.scatter_(dim= 1, src = 1, index = labels )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "18267b3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 10])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src  = torch.arange(1,11, dtype = torch.float32).reshape((2,5))\n",
    "index = torch.tensor([[0, 1, 2, 0]])\n",
    "target = torch.zeros(5,10,dtype = torch.float32)\n",
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "298c5d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 2., 3., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.scatter_(1, index, src )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "cd30a77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# --- Data for a simple linear regression problem ---\n",
    "# We want to learn the relationship: y = 3x_1 + 2x_2 + noise\n",
    "X = torch.randn(100, 2)\n",
    "noise = torch.randn(100, 1) * 0.1\n",
    "y = 3 * X[:, 0:1] + 2 * X[:, 1:2] + noise\n",
    "\n",
    "# --- Data for an embedding lookup problem ---\n",
    "# An embedding matrix for a vocabulary of size 10, with 4-dim vectors\n",
    "embedding_matrix = torch.rand(10, 4)\n",
    "\n",
    "# A batch of 2 \"sentences\", each with 5 word indices\n",
    "sentences_indices = torch.tensor([[1, 5, 2, 8, 0],\n",
    "                                  [3, 4, 6, 9, 7]], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326d5ab4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "fdd44fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1])\n",
      "0.00871671736240387\n"
     ]
    }
   ],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(2,1)\n",
    "    def forward(self, x):\n",
    "        y = self.linear(x)\n",
    "        return y \n",
    "model = LinearRegression()\n",
    "output = model(X)\n",
    "print(output.shape)\n",
    "loss = nn.MSELoss()\n",
    "optim = torch.optim.SGD(model.parameters(), lr = 0.01)\n",
    "for _ in range(1000):\n",
    "\n",
    "    y_hat = model(X)\n",
    "    mse_loss =loss(y_hat, y )\n",
    "    optim.zero_grad()\n",
    "    mse_loss.backward()\n",
    "    optim.step()\n",
    "    \n",
    "print(mse_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "fab3e0e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.0002], requires_grad=True)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.linear.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "13f49258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 4])"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# --- Data for an embedding lookup problem ---\n",
    "# An embedding matrix for a vocabulary of size 10, with 4-dim vectors\n",
    "embedding_matrix = torch.rand(10, 4)\n",
    "\n",
    "# A batch of 2 \"sentences\", each with 5 word indices\n",
    "sentences_indices = torch.tensor([[1, 5, 2, 8, 0],\n",
    "                                  [3, 4, 6, 9, 7]], dtype=torch.long)\n",
    "\n",
    "A = embedding_matrix[sentences_indices]\n",
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "1d5b903c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# --- Data for the new problems ---\n",
    "\n",
    "# A list of tensors, each representing a sentence with different lengths.\n",
    "# The numbers are word indices.\n",
    "sentences = [\n",
    "    torch.tensor([4, 1, 7, 2]),\n",
    "    torch.tensor([8, 2]),\n",
    "    torch.tensor([5, 9, 3, 6, 8, 1])\n",
    "]\n",
    "\n",
    "# A simple model you might have trained earlier (from previous questions)\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "77ce7ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Starter tensors\n",
    "a = torch.arange(24).reshape(2, 3, 4).float()\n",
    "b = torch.randn(2, 3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e74cad6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
