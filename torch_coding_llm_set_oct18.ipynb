{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b32c8fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0183)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conceptual: Cross-Entropy vs. KL Divergence\n",
    "# Answer:The Cross-Entropy \n",
    "# $H(P, Q)$ is $H(P, Q) = -\\sum P(x) \\log Q(x)$.\n",
    "# The KL Divergence $D_{KL}(P || Q)$ is $\\sum P(x) \\log\\left(\\frac{P(x)}{Q(x)}\\right)$.\n",
    "# If you expand the KL Divergence formula:DKL​(P∣∣Q)=∑P(x)logP(x)−∑P(x)logQ(x)DKL​(P∣∣Q)=−H(P)+H(P,Q)\n",
    "# This means $H(P, Q) = D_{KL}(P || Q) + H(P)$, where $H(P)$ is the entropy of the true distribution $P$.\n",
    "# The punchline: In classification, our true distribution $P$ is a one-hot vector (e.g., [0, 0, 1, 0]). \n",
    "# The entropy of this distribution, $H(P)$, is a constant 0.Therefore, for classification, \n",
    "# minimizing the Cross-Entropy is mathematically identical to minimizing the KL Divergence, \n",
    "# and Cross-Entropy is simpler to compute.\n",
    "# Assume a batch size of 2, with 3 classes\n",
    "import torch \n",
    "B, C = 2, 3\n",
    "# Model output (logits)\n",
    "logits_q = torch.tensor([\n",
    "    [0.5, 0.2, 0.3],  # Sample 1\n",
    "    [0.1, 0.8, 0.1]   # Sample 2\n",
    "])\n",
    "# Target output (logits)\n",
    "logits_p = torch.tensor([\n",
    "    [0.6, 0.1, 0.3],  # Sample 1\n",
    "    [0.1, 0.8, 0.1]   # Sample 2\n",
    "])\n",
    "\n",
    "log_probs_Q = torch.log_softmax(logits_q,dim = 1 )\n",
    "log_probs_P = torch.log_softmax(logits_p, dim = 1)\n",
    "kl_elements = log_probs_P - log_probs_Q\n",
    "kl_per_sample = torch.sum(logits_p*kl_elements, dim=1)\n",
    "torch.mean(kl_per_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d29de9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMS Norm \n",
    "N = 10 \n",
    "features = 14\n",
    "import torch.nn as nn \n",
    "X = torch.randn(N, features )\n",
    "# normalise using RMS norm \n",
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "        self.epsilon = 1e-6 \n",
    "        self.hidden_size = hidden_size\n",
    "        self.weights = nn.Parameter(torch.ones(hidden_size)) # this is the learnable part \n",
    "\n",
    "    def forward(self, X):\n",
    "        # last dimention of X is hidden size, so its N, hidden size lets say \n",
    "        rms = torch.sqrt(torch.mean(X**2,dim=-1,keepdim=True) + self.epsilon)\n",
    "        X = X/ rms\n",
    "        X = self.weights*X\n",
    "        \n",
    "        return X\n",
    "\n",
    "rmsnorm = RMSNorm(hidden_size=features)\n",
    "y=  rmsnorm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "015cf2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# layernorm \n",
    "# X is the same \n",
    "N = 14 \n",
    "features = 19\n",
    "X = torch.randn(N, features )\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, hidden_size, epsilon):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.epsilon = epsilon\n",
    "        self.beta = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.gamma = nn.Parameter(torch.ones(hidden_size))\n",
    "    def forward(self,X):\n",
    "        mean = torch.mean(X, dim= 1, keepdim=True)\n",
    "        #variance = torch.var(X, dim = 1, keepdim=True)\n",
    "        # torch.var() by default calculates the unbiased sample variance (using $N-1$ as the denominator).\n",
    "        variance = torch.mean((X - mean)**2, dim=-1, keepdim=True)\n",
    "        X = (X-mean)/torch.sqrt(variance+self.epsilon) \n",
    "        return self.gamma*X + self.beta\n",
    "\n",
    "\n",
    "layernorm = LayerNorm(hidden_size=features, epsilon= 1e-6)\n",
    "#layernorm(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "787893d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "# grouped query attention \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Synthetic data\n",
    "torch.manual_seed(42)\n",
    "batch_size = 3\n",
    "seq_len = 4\n",
    "d_model = 8\n",
    "num_heads = 2\n",
    "\n",
    "q = torch.rand(batch_size, seq_len, d_model)\n",
    "k = torch.rand(batch_size, seq_len, d_model)\n",
    "v = torch.rand(batch_size, seq_len, d_model)\n",
    "print(q.shape)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# lets do Multi Head, MutliQuery and Group Query \n",
    "# MHA: $N$ Query heads, $N$ Key heads, $N$ Value heads.\n",
    "# MQA: $N$ Query heads, $1$ Key head, $1$ Value head.\n",
    "# GQA: $N$ Query heads, $G$ Key heads, $G$ Value heads. \n",
    "# (Where $G$ is a small number, and $N$ is divisible by $G$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "42ce5f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 512 \n",
    "num_heads_q =8\n",
    "num_heads_kv = 2 \n",
    "head_dim = 64 \n",
    "# 2 K/V heads (So, 4 Q heads will share one K/V head)\n",
    "class GroupedQueryAttention(nn.Module):\n",
    "    def __init__(self, d_model: int, num_heads_q: int, num_heads_kv: int, head_dim: int):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model \n",
    "        self.num_heads_kv = num_heads_kv\n",
    "        self.num_heads_q = num_heads_q \n",
    "        self.head_dim = head_dim\n",
    "        self.q_dim = head_dim* num_heads_q\n",
    "        kv_dim = head_dim*num_heads_kv\n",
    "        self.num_groups = num_heads_q // num_heads_kv\n",
    "        # we need learnable parameters, for WQ, WK, WV and WO \n",
    "        self.Wq = nn.Linear(d_model,self.q_dim, bias = False) \n",
    "        self.Wk = nn.Linear(d_model, kv_dim, bias = False)\n",
    "        self.Wv = nn.Linear(d_model, kv_dim, bias = False)\n",
    "        self.Wo = nn.Linear(self.q_dim, d_model ,bias = False)\n",
    "    def forward(self,x, mask = False):\n",
    "        q = self.Wq(x) # batch , seq_len, q_dim\n",
    "        k = self.Wk(x) # batch , seq_len, kvdim\n",
    "        v = self.Wv(x) # batch , seq_len, kvdim\n",
    "        batch = x.shape[0]\n",
    "        q = q.view(batch, -1, self.num_heads_q,head_dim  ).transpose(1,2)\n",
    "        v = v.view(batch, -1, self.num_heads_kv,head_dim  ).transpose(1,2)\n",
    "        k = k.view(batch, -1, self.num_heads_kv,head_dim  ).transpose(1,2)\n",
    "        if self.num_groups>1:\n",
    "            k = k.repeat_interleave(self.num_groups, dim=1)\n",
    "            v = v.repeat_interleave(self.num_groups,dim=1)\n",
    "        # now all of them are in batch , num_heads_q , seq_len, head_dim \n",
    "            \n",
    "\n",
    "        scores = F.scaled_dot_product_attention(q, k, v , attn_mask=None).transpose(1,2).contiguous().view(batch, -1,self.q_dim )\n",
    "        output = self.Wo(scores)\n",
    "        return output\n",
    "X = torch.rand(10, 20, 512 )\n",
    "d_model = 512 \n",
    "num_heads_q =8\n",
    "num_heads_kv = 2 \n",
    "head_dim = 64 \n",
    "f = GroupedQueryAttention(d_model, num_heads_q, num_heads_kv, head_dim)\n",
    "y = f.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8d9a3ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 20, 512])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_model = 512 \n",
    "num_heads_q =8\n",
    "num_heads_kv = 2 \n",
    "head_dim = 64 \n",
    "# 2 K/V heads (So, 4 Q heads will share one K/V head)\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model: int, head_dim: int):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model \n",
    "       \n",
    "        self.head_dim = head_dim\n",
    "        self.n_heads = d_model//head_dim\n",
    "        self.Wq = nn.Linear(d_model,d_model ,bias = False) \n",
    "        self.Wk = nn.Linear(d_model, d_model, bias = False)\n",
    "        self.Wv = nn.Linear(d_model, d_model, bias = False)\n",
    "        self.Wo = nn.Linear(d_model, d_model ,bias = False)\n",
    "    def forward(self,x, mask = False):\n",
    "        q = self.Wq(x) # batch , seq_len, d_model\n",
    "        k = self.Wk(x) # batch , seq_len, d_model\n",
    "        v = self.Wv(x) # batch , seq_len, d_model\n",
    "        batch = x.shape[0]\n",
    "        q = q.view(batch, -1, self.n_heads, head_dim  ).transpose(1,2)\n",
    "        v = v.view(batch, -1, self.n_heads,head_dim  ).transpose(1,2)\n",
    "        k = k.view(batch, -1, self.n_heads,head_dim  ).transpose(1,2)\n",
    "        # if self.num_groups>1:\n",
    "        #     k = k.repeat_interleave(self.num_groups, dim=1)\n",
    "        #     v = v.repeat_interleave(self.num_groups,dim=1)\n",
    "        # now all of them are in batch , num_heads_q , seq_len, head_dim \n",
    "            \n",
    "\n",
    "        scores = F.scaled_dot_product_attention(q, k, v , attn_mask=None).transpose(1,2).contiguous().view(batch, -1,self.d_model )\n",
    "        output = self.Wo(scores)\n",
    "        return output\n",
    "X = torch.rand(10, 20, 512 )\n",
    "d_model = 512 \n",
    "head_dim = 64 \n",
    "f = MultiHeadAttention(d_model, head_dim)\n",
    "y = f.forward(X)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7eaf1301",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb = torch.tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
    "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
    "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
    "                [25, 17, 27, 10,  0, 21,  1, 54]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "42686dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "block_size = 32\n",
    "#!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "# here are all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "\n",
    "# Train and test splits\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "# data loading\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "16639e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "    def forward(self, idx, targets=None):\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        logits = self.token_embedding_table(idx) # (B,T,C)\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss\n",
    "    def generate(self,idx,  max_new_tokens=100):\n",
    "        # idx is the geenrations so far or the prompt B, \n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self(idx) \n",
    "            logits = logits[:, -1, : ]\n",
    "            probs = F.softmax(logits, dim = -1)\n",
    "            idx_next = torch.multinomial(probs, num_samples = 1 )\n",
    "            idx = torch.cat((idx, idx_next), dim = 1)\n",
    "        return idx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1ee7aa50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[41, 59, 40, 47, 52, 43,  8,  0,  0, 23, 21, 26, 19,  1, 17, 16, 35, 13,\n",
       "         30, 16,  1, 21, 34, 10,  0, 37, 53, 59,  1, 41, 39, 60],\n",
       "        [ 1, 57, 50, 39, 60, 43, 57,  6,  1, 21,  1, 41, 39, 52,  1, 58, 43, 50,\n",
       "         50,  1, 63, 53, 59,  1, 52, 43, 61, 57,  6,  7,  7,  1],\n",
       "        [47, 44, 43, 57, 58, 43, 42, 11,  0, 35, 46, 47, 41, 46,  6,  1, 58, 46,\n",
       "         53, 59, 45, 46,  1, 58, 46, 53, 59,  1, 61, 53, 59, 50]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "87b94c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = get_batch(\"train\")\n",
    "vocab_size= 65\n",
    "model = BigramLanguageModel(vocab_size)\n",
    "# yb = torch.tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
    "#         [53, 56,  1, 58, 46, 39, 58,  1],\n",
    "#         [58,  1, 58, 46, 39, 58,  1, 46],\n",
    "#         [17, 27, 10,  0, 21,  1, 54, 39]])\n",
    "logits, loss = model(xb,yb)\n",
    "y = model.generate(xb, 100 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c83af1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3859660625457764\n"
     ]
    }
   ],
   "source": [
    "# pytorch optimisation object \n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = 1e-3 )\n",
    "for i in range(10000):\n",
    "    xb,yb  = get_batch(\"train\")\n",
    "    logits, loss = model(xb,yb )\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(loss.item())\n",
    "\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "93417604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "plave athalprowfilaileno BAhezyothicod'he at cohe hrveldekod apt Ihe as o t; ig nd, Whes, th nd;\n",
      "Sthee manyoincedsare, inkiourext memo averel'd m p\n",
      "We?X;\n",
      "S:\n",
      "Whiomake t was ierast:\n",
      "\n",
      "'lsth te ond s wot w w!; ce;\n",
      "TCa ar I lll he o wn on on,\n",
      "OPny; Apondithe byowhoyeckisot Vo s ne u cof is co ntofougm I fue?\n",
      "OLHAMENNS:\n",
      "FzThy ffon:\n",
      "Hot t mnt wo n Yote?\n",
      "HESathe cr:\n",
      "INNGwel s\n",
      "SSS myomocad,\n",
      "Ked ofuthedsende ng\n",
      "KI:\n",
      "ARY g seRLe o-LARTIORoretrtithe?\n",
      "NS:\n",
      "Th wrtowrifous fes'se.\n",
      "Thamedes thes s yousho gr pitir je Y t ale; atwnolmy, tu cepithiel glese-ltim'd ded or ivincewisth:\n",
      "Bu hugeyowbe\n",
      "Byech IZve wan hirpres m cheat'd OPINe ss:\n",
      "Ylenournde avequt, pa y p, spldyoure thed\n",
      "\n",
      "Loffoukkericeprmea shrennow.\n",
      "Fad ow t bacerom breatthers ot IUSCOGLean g u iogo'th a, he. amom;\n",
      "Fin y boloute tulf a itou llal if:\n",
      "Bzandroveathou telve; bu ais WUENGLUET:\n",
      "Ay, avetcestit yo?--hes s Iowhato-the t s:\n",
      "Myofe sl.\n",
      "ANThad afus\n",
      "\n",
      "nou?\n",
      "Boof fime ady\n",
      "HEShonorse sh t f it by s, ory mpte fa t ke torw:\n",
      "Trear.\n",
      "\n",
      "yond?\n",
      "O:\n",
      "\n",
      "LI noguleiverodsel?-sheechenees akiss he bor onowo,\n",
      "RKI me-cey f anthe swim th aur.\n",
      "Kimulluren Vouen omerom be, pasisig h douayothoind a r veavtofoul ZO:\n",
      "INEESAKINThe asthie.\n",
      "The, hand te;\n",
      "\n",
      "CAntom Iveontrjood, s,\n",
      "an lise lls cthineathan! O:\n",
      "\n",
      "\n",
      "ORDrwinou brver Wea hanasf Sgipoket oucof lata'd; Le jQd tent at brt:\n",
      "I n sheld ld.\n",
      "S o at buroundshe wet br wng\n",
      "\n",
      "cistarMuirnavore\n",
      "Wil'YOrn, ablensu, olody inenknses h toochiescof ledom t.\n",
      "EERus lmeVIUTkf youpe w$cond t mpax3:\n",
      "H:\n",
      "MOro INENThaud, d frd Io!ZjEmyorrb; be,\n",
      "BOule, Le a\n",
      "Bu, dirranstinous'e bealld ilerintutl-l h\n",
      "Alcakie\n",
      "WouthenofQurch wqud, ASono bn winopollilocepeesarrr'sa!\n",
      "foand poce d?\n",
      "Thand ENF:\n",
      "\n",
      "Byorse s, stSpad;\n",
      "Hjo\n",
      "INEDr, is lavise Farthedolly akes he tan banouaveel tind cqand\n",
      "ak n.\n",
      "STo ayswn wrco iusatcul ngr, ant imalune, melWht sthaterose; byonerilZPUEm, cithe, S:\n",
      "how w't!\n",
      "MyCUCARME t; sind nwheas, es.y mnd pr lak is r hy wid t it:\n",
      "My owo!\n",
      "NThey, met d haril erke f me! he.\n",
      "Yonwire, he y fargerte moudeat, rer.\n",
      "W:\n",
      "FRDI:\n",
      "I vesulior pathet\n"
     ]
    }
   ],
   "source": [
    "print(decode(model.generate(context, max_new_tokens=2000)[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "6fdf2273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B, T , C = 4,8, 2\n",
    "torch.manual_seed(42)\n",
    "x = torch.randn(B,T,C)\n",
    "xbow = torch.zeros((B,T, C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        x_prev = x[b,:t+1]\n",
    "        xbow[b,t]= torch.mean(x_prev, 0 )\n",
    "a = torch.tril(torch.ones(T, T))\n",
    "a = a / a.sum(1, keepdim= True)\n",
    "y = a@x\n",
    "torch.allclose(xbow, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "1865c570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 \n",
    "tril = torch.tril(torch.ones(T, T)) \n",
    "wei = torch.zeros(T, T )\n",
    "wei = wei.masked_fill(tril==0, float(\"-inf\"))\n",
    "wei = F.softmax(wei, dim = -1 )\n",
    "xbow3 = wei@x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "34e294d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lora matrix \n",
    "d = 10 \n",
    "k = 10 \n",
    "import numpy as np \n",
    "W_rank = 2\n",
    "W = torch.randn(d, W_rank) @ torch.randn(W_rank, k)\n",
    "W_rank = np.linalg.matrix_rank(W)\n",
    "U, S, V = torch.svd(W)\n",
    "Ur = U[:, :W_rank]\n",
    "Sr = torch.diag(S[:W_rank])\n",
    "Vr = V[:, :W_rank].t()\n",
    "B = Ur@Sr\n",
    "A = Vr\n",
    "d = 10\n",
    "bias = torch.randn(d)\n",
    "x = torch.randn(d)\n",
    "y = (B@A)@x + bias \n",
    "y2 = W@x + bias \n",
    "print(W.numel())\n",
    "print(B.numel()+ A.numel())\n",
    "torch.allclose(y, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "3a259d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0651, -6.2567,  2.2067,  4.6670,  3.5105,  1.7308,  2.3720, -1.6852,\n",
       "         2.8738, -0.4953])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "294e36ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0651, -6.2567,  2.2067,  4.6670,  3.5105,  1.7308,  2.3720, -1.6852,\n",
       "         2.8738, -0.4953])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "efb7850b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.Size([2, 3, 1])\n",
      "torch.Size([2, 3, 4])\n",
      "torch.Size([1, 10])\n",
      "torch.Size([1, 10]) torch.Size([1, 10])\n",
      "torch.Size([10, 4, 3, 8])\n",
      "tensor([[-0.0427,  0.0239, -0.0104],\n",
      "        [ 0.1114,  0.0105,  0.0509],\n",
      "        [-0.0551,  0.0556,  0.0309],\n",
      "        [ 0.0179,  0.0057,  0.0958],\n",
      "        [-0.0476,  0.0057, -0.0829],\n",
      "        [ 0.0097, -0.1204, -0.0503],\n",
      "        [ 0.0721, -0.0390,  0.0262],\n",
      "        [-0.0077,  0.0022,  0.0396],\n",
      "        [-0.0360, -0.0171, -0.0558],\n",
      "        [-0.0221, -0.0195, -0.0934],\n",
      "        [ 0.0897, -0.1019, -0.0475],\n",
      "        [ 0.0301,  0.0503,  0.0614]])\n",
      "False\n",
      "tensor([ 2.1315, -2.3444,  0.7151,  1.5471, -1.7347,  1.0947, -1.1606, -0.8675,\n",
      "         0.7789, -1.3507,  0.4524, -0.3931,  1.0412, -1.0035,  1.5404,  1.3737,\n",
      "        -2.1651, -0.3115, -1.1131,  0.9503,  0.3048,  1.2917,  0.1542,  1.2265,\n",
      "        -0.1243, -0.9948, -0.9691,  0.8433,  1.1119, -1.4676])\n"
     ]
    }
   ],
   "source": [
    "# Tasks 1\n",
    "\n",
    "# Create a tensor x of shape (2, 3, 4).\n",
    "\n",
    "# Make y by summing over the last dim to shape (2, 3).\n",
    "\n",
    "# Make z so it broadcasts with y to add back into x without copying.\n",
    "\n",
    "# Given a with shape (10, 1), turn it into (1, 10) three different ways.\n",
    "\n",
    "# Take a batch image tensor imgs of shape (N, C, H, W) and permute it to (N, H, W, C).\n",
    "\n",
    "# Show why in-place ops can break autograd using +=.\n",
    "\n",
    "# Move a tensor to GPU if available, otherwise CPU.\n",
    "\n",
    "# Show the difference between view and reshape when the underlying storage isn’t contiguous.\n",
    "\n",
    "x = torch.randn(2,3 , 4)\n",
    "y = torch.sum(x, dim = -1)\n",
    "print(y.shape) # 2,3\n",
    "y1 = y.unsqueeze(2)\n",
    "print(y1.shape)\n",
    "z = x+y1\n",
    "print(z.shape)\n",
    "a = torch.randn(10,1)\n",
    "b = a.permute(1,0)\n",
    "print(b.shape)\n",
    "c = a.reshape(a.shape[1], a.shape[0])\n",
    "d = a.view(-1, a.shape[0])\n",
    "print(c.shape, d.shape)\n",
    "\n",
    "A = torch.randn(10, 3, 4, 8 )\n",
    "B = A.transpose(1,2)\n",
    "print(B.shape)\n",
    "# in place operations can break autograd \n",
    "X = torch.randn(12, 3, requires_grad=True)\n",
    "Y = X**2 \n",
    "Y+=1\n",
    "Z = torch.mean(Y+2)\n",
    "\n",
    "Z.backward()\n",
    "print(X.grad)\n",
    "# this works and gives an output of shape 12 3 \n",
    "# XX = torch.randn(12, 3, requires_grad=True)\n",
    "# YY = XX**2 \n",
    "# YY+=1\n",
    "# ZZ = 2\n",
    "# ZZ+= torch.mean(YY+2)\n",
    "# ZZ.backward()\n",
    "# XX.grad\n",
    "\n",
    "# Show the difference between view and reshape when the underlying storage isn’t contiguous.\n",
    "a_vector = torch.randn(10, 3)\n",
    "# this is true \n",
    "a_vector.is_contiguous()\n",
    "b_vector = a_vector.transpose(1, 0 )\n",
    "print(b_vector.is_contiguous()) # this is false \n",
    "#print(b_vector.view(-1, 30 ))# this needs the vector to be conitguous \n",
    "print(b_vector.reshape(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "57e3d80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9t/78vgfzf94l3f7wnvfk1ng3lc0000gq/T/ipykernel_13271/2585179518.py:7: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/build/aten/src/ATen/core/TensorBody.h:494.)\n",
      "  x.grad\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([2.0], requires_grad=True)\n",
    "x = x +1\n",
    "y = x * x\n",
    "y += 1  # modifies y in place\n",
    "z = y * x\n",
    "z.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "039ac0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(4, requires_grad=True)\n",
    "y = x**2\n",
    "z = y.mean()\n",
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abb6fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this iis the forward passs\n",
      "throwing checkpoints\n",
      "tensor([[ 0.7021,  0.4966, -1.7743, -1.1046, -0.0101,  0.4191, -0.6398, -0.6989,\n",
      "         -0.7336, -0.1511],\n",
      "        [-1.3401, -0.6799,  1.6131,  0.7541,  0.7405,  0.9105,  0.5754,  0.5524,\n",
      "         -0.4698,  0.5182],\n",
      "        [ 1.0117, -0.9354,  0.4439,  1.4630,  0.2563, -0.6287,  0.2358, -0.2923,\n",
      "          0.8597, -1.0530],\n",
      "        [ 0.5218, -0.1538, -0.5312,  0.1068,  0.0176, -0.6218, -0.2450,  0.0115,\n",
      "         -0.9111,  0.3211]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# show that the checkpoint works\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "def checkpoint_function(x):# this will throw away the computations fro activations if enabled \n",
    "    print(\"throwing checkpoints\")\n",
    "    return x*2\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(10,10)\n",
    "    def forward(self, x):\n",
    "        print(\"this iis the forward passs\")\n",
    "        x = checkpoint(checkpoint_function, x, use_reentrant=False)  # if set to false u can use the activations from thsi again, means there is no checkpoitning  \n",
    "        # by default this is true, but to checkpoiutn we set this to True # so we run the forward again if we can enteer again \n",
    "        return self.linear(x)\n",
    "model = MyModel()\n",
    "x = torch.randn(4, 10, requires_grad=True)\n",
    "y = model(x)\n",
    "print(y)\n",
    "y.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "b0ccff7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 16])\n"
     ]
    }
   ],
   "source": [
    "# Q1. Create a 3-layer MLP in PyTorch (no Sequential) with ReLU activations, input dim 16, hidden 32, output 10. \n",
    "# Forward should take (batch, 16) and return (batch, 10).\n",
    "\n",
    "# Q2. Write a training loop for 5 epochs using MSELoss and Adam optimizer. Use random tensors for both input and target. Print loss every epoch.\n",
    "torch.manual_seed(42)\n",
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(16, 32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(32, 10 )\n",
    "        self.batchnorm = nn.BatchNorm1d(10)\n",
    "        self.dropout  = nn.Dropout(0.9)\n",
    "    def forward(self, x):\n",
    "        # shape of forward is batch , 16 \n",
    "        layer1 = self.l1(x) # shape is batch , 32 \n",
    "        relu = self.relu(layer1)\n",
    "        layer2 = self.l2(relu )\n",
    "        layer_after_drop = self.dropout(layer2)\n",
    "        layer_after_drop = self.batchnorm(layer_after_drop)\n",
    "        return layer_after_drop\n",
    "batch = 10 \n",
    "X  = torch.randn(batch, 16 )\n",
    "y = torch.randn(batch ,10 )\n",
    "print(X.shape)\n",
    "n_epochs = 5\n",
    "loss = nn.MSELoss()\n",
    "model = MLP()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3 )\n",
    "model.train()\n",
    "for _ in range(n_epochs):\n",
    "    \n",
    "    logits = model(X)\n",
    "    \n",
    "    loss_ = loss(logits, y) \n",
    "    for param in model.parameters():\n",
    "        loss_+= torch.norm(param)**2\n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    loss_.backward() \n",
    "    \n",
    "    # clip the gradients \n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm = 1.0)\n",
    "    \n",
    "    optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "88a90411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean ≈ -0.0027171927504241467 train std ≈ 1.4131661653518677\n",
      "eval  mean ≈ -0.0038609839975833893 eval  std ≈ 1.0004689693450928\n"
     ]
    }
   ],
   "source": [
    "import torch, torch.nn as nn\n",
    "torch.manual_seed(0)\n",
    "\n",
    "x = torch.randn(10000, 32)  # large batch to smooth randomness\n",
    "drop = nn.Dropout(p=0.5)\n",
    "\n",
    "# Train mode: dropout active, survivors scaled by 1/(1-p)=2\n",
    "drop.train()\n",
    "yt = drop(x)\n",
    "print(\"train mean ≈\", yt.mean().item(), \"train std ≈\", yt.std().item())\n",
    "\n",
    "# Eval mode: dropout off\n",
    "drop.eval()\n",
    "ye = drop(x)\n",
    "print(\"eval  mean ≈\", ye.mean().item(), \"eval  std ≈\", ye.std().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "07c40c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[-6.4725e-01,  9.2750e-02, -4.7973e-02, -1.0900e+00],\n",
      "        [ 1.8613e-01, -9.8721e-05, -7.0357e-01, -1.0379e+00],\n",
      "        [ 7.3243e-01,  3.9538e-01,  4.6574e-01,  1.9137e-01]],\n",
      "       requires_grad=True)\n",
      "Analytical gradient (autograd): tensor([[1.2568e+00, 2.5808e-02, 6.9044e-03, 3.5644e+00],\n",
      "        [1.0393e-01, 2.9237e-08, 1.4850e+00, 3.2317e+00],\n",
      "        [1.6094e+00, 4.6897e-01, 6.5073e-01, 1.0987e-01]])\n"
     ]
    }
   ],
   "source": [
    "# autograd \n",
    "class Autograd(torch.autograd.Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        ctx.save_for_backward(x)\n",
    "        return x**3 \n",
    "    @staticmethod\n",
    "    def backward(ctx,grad_output):\n",
    "        x, = ctx.saved_tensors\n",
    "        return 3*grad_output*x**2\n",
    "\n",
    "# Use the function\n",
    "x = torch.randn(3, 4, requires_grad=True)\n",
    "y = Autograd.apply(x)\n",
    "y.sum().backward()\n",
    "\n",
    "print(\"x:\", x)\n",
    "print(\"Analytical gradient (autograd):\", x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c4431c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4])\n",
      "x: tensor([[ 0.3738,  3.2050,  1.3382, -1.0091],\n",
      "        [ 0.1184, -2.1165,  0.0848, -1.8846],\n",
      "        [-0.6045, -0.8623,  0.0271, -0.0036]], requires_grad=True)\n",
      "Analytical gradient (autograd): tensor([[ 0.6826,  1.0811,  1.0125,  0.0696],\n",
      "        [ 0.5591, -0.0956,  0.5424, -0.0839],\n",
      "        [ 0.2152,  0.1169,  0.5135,  0.4982]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9t/78vgfzf94l3f7wnvfk1ng3lc0000gq/T/ipykernel_13271/1116255677.py:27: DeprecationWarning: <class '__main__.Swish'> should not be instantiated. Methods on autograd functions are all static, so you should invoke them on the class itself. Instantiating an autograd function will raise an error in a future version of PyTorch.\n",
      "  self.layer2 =  Swish()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3])"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# autograd \n",
    "def sigmoid(x):\n",
    "    return 1/ (1+torch.exp(-x))\n",
    "class Swish(torch.autograd.Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        ctx.save_for_backward(x)\n",
    "        return x*sigmoid(x)\n",
    "    @staticmethod\n",
    "    def backward(ctx,grad_output):\n",
    "        x, = ctx.saved_tensors\n",
    "        return grad_output*(sigmoid(x)+ x*sigmoid(x)*(1-sigmoid(x)) )\n",
    "\n",
    "# Use the function\n",
    "x = torch.randn(3, 4, requires_grad=True)\n",
    "y = Swish.apply(x)\n",
    "print(y.shape)\n",
    "y.sum().backward()\n",
    "\n",
    "print(\"x:\", x)\n",
    "print(\"Analytical gradient (autograd):\", x.grad)\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(8,16)\n",
    "        self.layer2 =  Swish()\n",
    "        self.layer3 = nn.Linear(16,3)\n",
    "    def forward(self, x):\n",
    "        y = self.layer1(x)\n",
    "        y = self.layer3(self.layer2.apply(y))\n",
    "        return y \n",
    "x = torch.randn(10, 8)\n",
    "model = MLP()\n",
    "loss = nn.CrossEntropyLoss() # this takes the logits \n",
    "output = model(x)\n",
    "loss_ = loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "1e3f80fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# 1. Create two random tensors of shape (64, 100)\n",
    "A = torch.randn(64, 100)\n",
    "B = torch.randn(64, 100)\n",
    "C = A[:, :20 ]\n",
    "D = B[:, -30:]\n",
    "E = torch.cat([C, D], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "3b3ff886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 224, 224])\n",
      "torch.float32 cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.randn(8, 3, 224, 224)  # batch of 8 RGB images\n",
    "print(x.shape)  # torch.Size([8, 3, 224, 224])\n",
    "print(x.dtype, x.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824b86ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7. Minimal custom layer (10 pts)\n",
    "# Write a tiny nn.Module called ScaledLinear that:\n",
    "\n",
    "# takes in_features, out_features, scale in __init__\n",
    "\n",
    "# computes y = scale * (x @ W.T + b)\n",
    "# Properly register parameters, set a Kaiming-uniform init for W, zeros for b. \n",
    "# Keep device/dtype-safe (i.e., use register_buffer for scale if it’s a float).\n",
    "\n",
    "class ScaledLinear(nn.Module):\n",
    "    def __init__(self,in_features, out_features, scale):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.scale = scale \n",
    "        self.weight = nn.Parameter(torch.randn(in_features, out_features))\n",
    "        self.bias = nn.Parameter(torch.zeros(out_features))\n",
    "        self.register_buffer(self.scale)\n",
    "        #self.Weight = nn.Linear(in_features, out_features, bias = True)\n",
    "    def forward(self, X):\n",
    "        # assume X is hte shape  N, in_features\n",
    "        y = X@self.weight + self.bias \n",
    "        return self.scale*y \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "47ca0c98",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'type' object does not support the context manager protocol",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[391]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Write a correct training step using torch.cuda.amp.autocast and GradScaler. \u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Assume model, optimizer, scaler, images, targets, criterion exist.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m.\u001b[49m\u001b[43mamp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautocast\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mset_to_none\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: 'type' object does not support the context manager protocol"
     ]
    }
   ],
   "source": [
    "# Write a correct training step using torch.cuda.amp.autocast and GradScaler. \n",
    "# Assume model, optimizer, scaler, images, targets, criterion exist.\n",
    "with torch.cuda.amp.autocast :\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    logits = model(x)\n",
    "    loss  = ce_loss(logits, labels)\n",
    "    # we scale the gradients\n",
    "    scaler.scale(loss)\n",
    "    loss.backward()\n",
    "    scaler.update()\n",
    "    optimizer.step()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "cb768603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch._logging.set_logs(graph_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "fee53ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo(x, y):\n",
    "    a = torch.sin(x)\n",
    "    b = torch.cos(y)\n",
    "    return a + b\n",
    "opt_foo1 = torch.compile(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "7311d651",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "V1019 14:10:15.066000 13271 site-packages/torch/_dynamo/output_graph.py:1667] [0/0] [__graph_code] TRACED GRAPH\n",
      "V1019 14:10:15.066000 13271 site-packages/torch/_dynamo/output_graph.py:1667] [0/0] [__graph_code]  ===== __compiled_fn_1_cdd1ceef_e6fd_4bb3_bfe0_6e4dc55a0b69 =====\n",
      "V1019 14:10:15.066000 13271 site-packages/torch/_dynamo/output_graph.py:1667] [0/0] [__graph_code]  /Users/pchiniya/Desktop/hoverboard_workspace/mine/.conda/lib/python3.11/site-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "V1019 14:10:15.066000 13271 site-packages/torch/_dynamo/output_graph.py:1667] [0/0] [__graph_code]     def forward(self, L_x_: \"f32[3, 3][3, 1]cpu\", L_y_: \"f32[3, 3][3, 1]cpu\"):\n",
      "V1019 14:10:15.066000 13271 site-packages/torch/_dynamo/output_graph.py:1667] [0/0] [__graph_code]         l_x_ = L_x_\n",
      "V1019 14:10:15.066000 13271 site-packages/torch/_dynamo/output_graph.py:1667] [0/0] [__graph_code]         l_y_ = L_y_\n",
      "V1019 14:10:15.066000 13271 site-packages/torch/_dynamo/output_graph.py:1667] [0/0] [__graph_code]         \n",
      "V1019 14:10:15.066000 13271 site-packages/torch/_dynamo/output_graph.py:1667] [0/0] [__graph_code]          # File: /var/folders/9t/78vgfzf94l3f7wnvfk1ng3lc0000gq/T/ipykernel_13271/3539289742.py:2 in foo, code: a = torch.sin(x)\n",
      "V1019 14:10:15.066000 13271 site-packages/torch/_dynamo/output_graph.py:1667] [0/0] [__graph_code]         a: \"f32[3, 3][3, 1]cpu\" = torch.sin(l_x_);  l_x_ = None\n",
      "V1019 14:10:15.066000 13271 site-packages/torch/_dynamo/output_graph.py:1667] [0/0] [__graph_code]         \n",
      "V1019 14:10:15.066000 13271 site-packages/torch/_dynamo/output_graph.py:1667] [0/0] [__graph_code]          # File: /var/folders/9t/78vgfzf94l3f7wnvfk1ng3lc0000gq/T/ipykernel_13271/3539289742.py:3 in foo, code: b = torch.cos(y)\n",
      "V1019 14:10:15.066000 13271 site-packages/torch/_dynamo/output_graph.py:1667] [0/0] [__graph_code]         b: \"f32[3, 3][3, 1]cpu\" = torch.cos(l_y_);  l_y_ = None\n",
      "V1019 14:10:15.066000 13271 site-packages/torch/_dynamo/output_graph.py:1667] [0/0] [__graph_code]         \n",
      "V1019 14:10:15.066000 13271 site-packages/torch/_dynamo/output_graph.py:1667] [0/0] [__graph_code]          # File: /var/folders/9t/78vgfzf94l3f7wnvfk1ng3lc0000gq/T/ipykernel_13271/3539289742.py:4 in foo, code: return a + b\n",
      "V1019 14:10:15.066000 13271 site-packages/torch/_dynamo/output_graph.py:1667] [0/0] [__graph_code]         add: \"f32[3, 3][3, 1]cpu\" = a + b;  a = b = None\n",
      "V1019 14:10:15.066000 13271 site-packages/torch/_dynamo/output_graph.py:1667] [0/0] [__graph_code]         return (add,)\n",
      "V1019 14:10:15.066000 13271 site-packages/torch/_dynamo/output_graph.py:1667] [0/0] [__graph_code]         \n",
      "V1019 14:10:15.066000 13271 site-packages/torch/_dynamo/output_graph.py:1667] [0/0] [__graph_code] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.1524, 1.4718, 0.6141],\n",
       "        [0.1689, 0.6164, 0.0785],\n",
       "        [1.0145, 1.9452, 1.0423]])"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_foo1(torch.randn(3, 3), torch.randn(3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "b40fff11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "V1019 14:14:57.784000 13271 site-packages/torch/_dynamo/output_graph.py:1667] [1/0] [__graph_code] TRACED GRAPH\n",
      "V1019 14:14:57.784000 13271 site-packages/torch/_dynamo/output_graph.py:1667] [1/0] [__graph_code]  ===== __compiled_fn_3_e5554d5c_6eca_4911_9ce2_d3aceeaf93d5 =====\n",
      "V1019 14:14:57.784000 13271 site-packages/torch/_dynamo/output_graph.py:1667] [1/0] [__graph_code]  /Users/pchiniya/Desktop/hoverboard_workspace/mine/.conda/lib/python3.11/site-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module):\n",
      "V1019 14:14:57.784000 13271 site-packages/torch/_dynamo/output_graph.py:1667] [1/0] [__graph_code]     def forward(self, L_x_: \"f32[3, 3][3, 1]cpu\", L_y_: \"f32[3, 3][3, 1]cpu\"):\n",
      "V1019 14:14:57.784000 13271 site-packages/torch/_dynamo/output_graph.py:1667] [1/0] [__graph_code]         l_x_ = L_x_\n",
      "V1019 14:14:57.784000 13271 site-packages/torch/_dynamo/output_graph.py:1667] [1/0] [__graph_code]         l_y_ = L_y_\n",
      "V1019 14:14:57.784000 13271 site-packages/torch/_dynamo/output_graph.py:1667] [1/0] [__graph_code]         \n",
      "V1019 14:14:57.784000 13271 site-packages/torch/_dynamo/output_graph.py:1667] [1/0] [__graph_code]          # File: /var/folders/9t/78vgfzf94l3f7wnvfk1ng3lc0000gq/T/ipykernel_13271/4220512634.py:3 in opt_foo2, code: a = torch.sin(x)\n",
      "V1019 14:14:57.784000 13271 site-packages/torch/_dynamo/output_graph.py:1667] [1/0] [__graph_code]         a: \"f32[3, 3][3, 1]cpu\" = torch.sin(l_x_);  l_x_ = None\n",
      "V1019 14:14:57.784000 13271 site-packages/torch/_dynamo/output_graph.py:1667] [1/0] [__graph_code]         \n",
      "V1019 14:14:57.784000 13271 site-packages/torch/_dynamo/output_graph.py:1667] [1/0] [__graph_code]          # File: /var/folders/9t/78vgfzf94l3f7wnvfk1ng3lc0000gq/T/ipykernel_13271/4220512634.py:4 in opt_foo2, code: b = torch.cos(y)\n",
      "V1019 14:14:57.784000 13271 site-packages/torch/_dynamo/output_graph.py:1667] [1/0] [__graph_code]         b: \"f32[3, 3][3, 1]cpu\" = torch.cos(l_y_);  l_y_ = None\n",
      "V1019 14:14:57.784000 13271 site-packages/torch/_dynamo/output_graph.py:1667] [1/0] [__graph_code]         \n",
      "V1019 14:14:57.784000 13271 site-packages/torch/_dynamo/output_graph.py:1667] [1/0] [__graph_code]          # File: /var/folders/9t/78vgfzf94l3f7wnvfk1ng3lc0000gq/T/ipykernel_13271/4220512634.py:5 in opt_foo2, code: return a + b\n",
      "V1019 14:14:57.784000 13271 site-packages/torch/_dynamo/output_graph.py:1667] [1/0] [__graph_code]         add: \"f32[3, 3][3, 1]cpu\" = a + b;  a = b = None\n",
      "V1019 14:14:57.784000 13271 site-packages/torch/_dynamo/output_graph.py:1667] [1/0] [__graph_code]         return (add,)\n",
      "V1019 14:14:57.784000 13271 site-packages/torch/_dynamo/output_graph.py:1667] [1/0] [__graph_code]         \n",
      "V1019 14:14:57.784000 13271 site-packages/torch/_dynamo/output_graph.py:1667] [1/0] [__graph_code] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6722,  1.7498, -0.2148],\n",
      "        [ 0.1570, -0.7484,  0.1241],\n",
      "        [ 0.9981,  1.6794, -0.2474]])\n"
     ]
    }
   ],
   "source": [
    "@torch.compile\n",
    "def opt_foo2(x, y):\n",
    "    a = torch.sin(x)\n",
    "    b = torch.cos(y)\n",
    "    return a + b\n",
    "\n",
    "\n",
    "print(opt_foo2(torch.randn(3, 3), torch.randn(3, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "d36f0b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pchiniya/Desktop/hoverboard_workspace/mine/.conda/lib/python3.11/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "from torch.utils.checkpoint import checkpoint # for activation checkpoitning \n",
    "from torch.nn.utils import clip_grad_norm_ # for clipping before update \n",
    "from torch.amp import autocast, GradScaler\n",
    "class ToyBlock(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, in_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return x\n",
    "class ToyModel(nn.Module):\n",
    "    def __init__(self, in_dim=128, hidden_dim=256):\n",
    "        super().__init__()\n",
    "        self.big_block = ToyBlock(in_dim, hidden_dim)\n",
    "        self.head = nn.Linear(in_dim, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.big_block(x)\n",
    "        return self.head(h)\n",
    "device = \"cpu\"\n",
    "accum_steps = 4       # gradient accumulation factor\n",
    "max_grad_norm = 1.0   # clipping threshold\n",
    "n_batches = 20        # simulate 20 batches\n",
    "model = ToyModel().to(device=device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "scaler = GradScaler()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model.train()\n",
    "optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "X = torch.randn(64, 128, device=device)\n",
    "Y = torch.randint(0, 10, (64,), device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "47af8aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_block(x):\n",
    "    return model(x)\n",
    "# checkpoint recomputes activations in backward, saves memory\n",
    "with autocast(device_type=\"cpu\"):\n",
    "    logits  = checkpoint(run_block, X, use_reentrant=False)\n",
    "    loss = criterion(logits, Y)\n",
    "    \n",
    "scaler.scale(loss).backward()\n",
    "scaler.unscale_(optimizer)\n",
    "clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "\n",
    "scaler.step(optimizer)\n",
    "scaler.update()\n",
    "optimizer.zero_grad(set_to_none=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00230ca0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622b64ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 64])\n"
     ]
    }
   ],
   "source": [
    "n_samples = 100 \n",
    "n_features = 64\n",
    "X = torch.randn((n_samples, n_features))\n",
    "k = 4 \n",
    "n_iter = 20\n",
    "# start with k random centroids \n",
    "centroids = X[torch.randperm(n_samples)[:k]] # k, n_features #O(n)\n",
    "# get the closest points to these centroids \n",
    "centroids = centroids.unsqueeze(1)\n",
    "print(centroids.shape)\n",
    "for i in range(n_iter):\n",
    "    old_centroids = centroids.clone()\n",
    "    euclidean_distances = torch.sqrt(torch.sum((X-centroids)**2, dim = -1)) # k X N \n",
    "    # so now we need to get labels for each datapoitn like where do they belong\n",
    "    # we need to know what data points belong to cluster 0 , 1, 2, 3 \n",
    "    cluster_indices = torch.argmin(euclidean_distances, dim = 0)\n",
    "    for i in range(k):\n",
    "        points = X[cluster_indices==i]\n",
    "        # poitns will be a tensor of x, features \n",
    "        centroids[i] = torch.mean(points, dim = 0 )\n",
    "    if torch.allclose(old_centroids, centroids):\n",
    "        break \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "b456880e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_predict(X_train, y_train, X_test, k=3):\n",
    "    # x train is of shape N, d \n",
    "    # y train fro shape N \n",
    "    # X_test is for B, d \n",
    "    X_test = X_test.unsqueeze(1) # so its now B, 1, d \n",
    "    euclidean_distances = torch.sum( (X_train - X_test)**2, dim = 2 )\n",
    "    # B, N\n",
    "    topk_labels,topk_indices = torch.topk(euclidean_distances, k=k, dim = 1, largest = False)\n",
    "    # so this is B,k \n",
    "    # so for this the label for each is final mod for dim 1\n",
    "    final_labels, _ = torch.mode(y_train[topk_indices])\n",
    "    return final_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "55d38642",
   "metadata": {},
   "outputs": [],
   "source": [
    "N, B, d = 100, 10, 64\n",
    "X_train = torch.randn(N, d )\n",
    "y_train = torch.randint(0,2, size=(N,))\n",
    "X_test = torch.randn(B, d)\n",
    "\n",
    "y = knn_predict(X_train, y_train, X_test, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb249f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 0, 0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def linear_forward(X, W, b):\n",
    "    # (N, in_features)\n",
    "    # (in_features, out_features)\n",
    "    # (out_features,)\n",
    "    y = X@W+b\n",
    "    return y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfd6cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def scaled_dot_product_attention(Q, K, V, mask=None):\n",
    "    # given Q, K, V vectores we implemetn scaled dot product attneitn \n",
    "    dk = K.shape[-1]\n",
    "    scores = torch.matmul(Q, K.transpose(1,2)) #N, seq_len, seq_len \n",
    "    \n",
    "    scores = scores/ math.sqrt(dk)\n",
    "    if mask is not None:\n",
    "        scores= scores.masked_fill(mask==0, float(\"-inf\"))\n",
    "    # N, seqlen, seqlen scores \n",
    "    # V is N,\n",
    "    scores = nn.functional.softmax(scores, dim = -1)\n",
    "    print(scores.shape)\n",
    "    weights = torch.matmul(scores, V) \n",
    "    return weights , scores\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "c7328af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len_q = seq_len_k = seq_len_v = 100\n",
    "d_k = d_v = d_q = 64\n",
    "N = 32\n",
    "Q = torch.randn((N, seq_len_q, d_k))\n",
    "K = torch.randn((N, seq_len_k, d_k))\n",
    "V = torch.randn((N, seq_len_k, d_v))\n",
    "mask = torch.tril(torch.randn(N, 1, 1, seq_len_k))\n",
    "mask_decoder = torch.tril(torch.randn((N, 1, seq_len_q, seq_len_k)))\n",
    "#scaled_dot_product_attention(Q, K, V, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b2e029",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model ,h ):\n",
    "        super().__init__() # to import form the super class \n",
    "        self.d_model = d_model \n",
    "        self.h = h \n",
    "        assert d_model% h ==0 \n",
    "        self.head_dim  = d_model// h \n",
    "        self.W_q= nn.Linear(d_model, d_model, bias = False)\n",
    "        self.W_k =nn.Linear(d_model, d_model, bias = False)\n",
    "        self.W_v = nn.Linear(d_model, d_model, bias = False)\n",
    "        self.W_o = nn.Linear(d_model, d_model, bias = False)\n",
    "    def forward(self, query, key , value, mask = None):\n",
    "        # calculate the projects fro the learnable matrices for Qk V \n",
    "        query = self.W_q(query)\n",
    "        key = self.W_k(key)\n",
    "        value = self.W_v(value)\n",
    "        batch , seq, dk = key.shape\n",
    "\n",
    "        # split into heads for parallel compuations \n",
    "        query = query.view(batch, seq, self.h, self.head_dim ).transpose(1, 2)\n",
    "        value  = value.view(batch, seq, self.h, self.head_dim ).transpose(1, 2)\n",
    "        key = key.view(batch, seq, self.h, self.head_dim ).transpose(1, 2)\n",
    "\n",
    "        # now these can go in to the function above \n",
    "        outputs, scores = scaled_dot_product_attention(query, key , value , mask )\n",
    "        # batch, seq, self.h, self.head_dim\n",
    "        outputs = self.W_o(outputs.transpose(1,2).contiguous().view(batch, seq, self.d_model))\n",
    "        return outputs, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf81805",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, h, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.h = h \n",
    "        self.dff = d_ff \n",
    "        assert d_model% h ==0 \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.mha = MultiHeadAttention(d_model, h)\n",
    "        self.layernorm1 = nn.LayerNorm(d_model)\n",
    "        self.layernorm2 = nn.LayerNorm(d_model)\n",
    "        self.FFN = nn.Sequential(nn.Linear(d_model, d_ff),\n",
    "                                 nn.ReLU(),\n",
    "                                   nn.Linear(d_ff, d_model))\n",
    "        self._init_weights()\n",
    "    def _init_weights(self):\n",
    "        for layer in self.modules():\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.xavier_uniform_(layer.weight)\n",
    "            if layer.bias is not None:\n",
    "                nn.init.constant_(layer.bias, 0 )\n",
    "                \n",
    "    def forward(self, x, mask=None):\n",
    "        # in encoder the inputs will be the same \n",
    "        # N, S, d_model \n",
    "        x_norm = self.layernorm1(x)\n",
    "        attention_output, attention_weights = self.mha(x_norm, x_norm, x_norm, mask )\n",
    "        x = x+ self.dropout(attention_output)\n",
    "\n",
    "        # second vlock for layernorm \n",
    "        residual = x \n",
    "        ffn_output = self.FFN(self.layernorm2(x))\n",
    "        x = residual + self.dropout(ffn_output)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841da8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self,n_layers,  d_model, h, d_ff,vocab_size, max_seq_len, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.h = h \n",
    "        self.vocab_size = vocab_size\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.dff = d_ff \n",
    "        assert d_model% h ==0 \n",
    "        self.tok_emb = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_emb = nn.Embedding(max_seq_len, d_model)\n",
    "        self.layers = nn.ModuleList([TransformerEncoderLayer(d_model, h, d_ff,dropout) \n",
    "                                    for _ in range(n_layers)])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.layernorm1 = nn.LayerNorm(d_model)\n",
    "                \n",
    "    def forward(self, x, mask=None):\n",
    "        # in encoder the inputs will be the same \n",
    "        # N, seq_len \n",
    "        N, S = x.shape\n",
    "        positions = torch.arange(0,S, device=x.device)\n",
    "        pos = self.pos_emb(positions)\n",
    "        token_emb = self.tok_emb(x)\n",
    "\n",
    "        x_ = pos+ token_emb\n",
    "        x = self.dropout(x_)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask )\n",
    "        x = self.layernorm1(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2298c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, h, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.h = h \n",
    "        self.dff = d_ff \n",
    "        assert d_model% h ==0 \n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dropout3 = nn.Dropout(dropout)\n",
    "        self.self_attn = MultiHeadAttention(d_model, h)\n",
    "        self.cross_attention = MultiHeadAttention(d_model, h)\n",
    "        self.layernorm1 = nn.LayerNorm(d_model)\n",
    "        self.layernorm2 = nn.LayerNorm(d_model)\n",
    "        self.layernorm3 = nn.LayerNorm(d_model)\n",
    "        self.FFN = nn.Sequential(nn.Linear(d_model, d_ff),\n",
    "                                 nn.ReLU(),\n",
    "                                   nn.Linear(d_ff, d_model))\n",
    "                \n",
    "    def forward(self, x, enc_output, lookahead_mask, padding_mask=None):\n",
    "        # in encoder the inputs will be the same \n",
    "        # N, S, d_model \n",
    "        x_norm = self.layernorm1(x)\n",
    "        attention_output, _ = self.self_attn(x_norm, x_norm, x_norm, lookahead_mask )\n",
    "        x = x+self.dropout1(attention_output)\n",
    "\n",
    "        x_norm2 = self.layernorm2(x)\n",
    "        cross_attention_output, _ = self.cross_attention(x_norm2,enc_output, enc_output, padding_mask )\n",
    "        x = x + self.dropout2(cross_attention_output)\n",
    "        \n",
    "        x_norm3 = self.layernorm3(x)\n",
    "        ffn_output = self.FFN(x_norm3)\n",
    "        x = x + self.dropout3(ffn_output)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69813f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.checkpoint import checkpoint\n",
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self,n_layers,  d_model, h, d_ff,vocab_size, max_seq_len, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.h = h \n",
    "        self.vocab_size = vocab_size\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.dff = d_ff \n",
    "        assert d_model% h ==0 \n",
    "        self.tok_emb = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_emb = nn.Embedding(max_seq_len, d_model)\n",
    "        self.layers = nn.ModuleList([TransformerDecoderLayer(d_model, h, d_ff,dropout) \n",
    "                                    for _ in range(n_layers)])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.layernorm1 = nn.LayerNorm(d_model)\n",
    "                \n",
    "    def forward(self, x, enc_output, lookahead_mask, padding_mask=None):\n",
    "        # in encoder the inputs will be the same \n",
    "        # N, seq_len \n",
    "        N, S = x.shape\n",
    "        positions = torch.arange(0,S, device=x.device)\n",
    "        pos = self.pos_emb(positions)\n",
    "        token_emb = self.tok_emb(x)\n",
    "\n",
    "        x_ = pos+ token_emb\n",
    "        x = self.dropout(x_)\n",
    "        for layer in self.layers:\n",
    "            x = checkpoint(lambda input_x: layer(input_x, enc_output, lookahead_mask, padding_mask),x, use_reentrant=False)\n",
    "        x = self.layernorm1(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "id": "3a7bf547",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9t/78vgfzf94l3f7wnvfk1ng3lc0000gq/T/ipykernel_13271/765945289.py:20: DeprecationWarning: <class '__main__.MyReLUFunction'> should not be instantiated. Methods on autograd functions are all static, so you should invoke them on the class itself. Instantiating an autograd function will raise an error in a future version of PyTorch.\n",
      "  gradient = MyReLUFunction()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 0])"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyReLUFunction(torch.autograd.Function):\n",
    "    # this must inherit from a autograd class \n",
    "    # we have to call the super to handle the upper class functions \n",
    "    # super().__init__\n",
    "    # this a static method which should be defined to have no leanrable parametrs\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        # ctx is hte context object to keep track of the inputs \n",
    "        ctx.save_for_backward(input)\n",
    "        return torch.clamp(input, min=0)\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        inputs = ctx.saved_tensors\n",
    "        if inputs >0:\n",
    "            return  grad_input*1 \n",
    "        else:\n",
    "            return 0 \n",
    "    \n",
    "    \n",
    "gradient = MyReLUFunction()\n",
    "gradient.apply(torch.tensor([1,2,3 , -1]))\n",
    "# You don't call super().__init__() because torch.autograd.Function has no state.\n",
    "# ctx is th etemoirtary satte that the autograd passes from forward to backward \n",
    "#The .apply() method is magically created by the base class (torch.autograd.Function).\n",
    "#You inherit .apply() just by subclassing. It's the \"magic\" that connects your functions to PyTorch's computation graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "id": "d75f6903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.5000, 3.7000, 9.0000])"
      ]
     },
     "execution_count": 612,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([-2.0, 0.5, 3.7, 10.0])\n",
    "torch.clamp(x, min=0,max = 9 )\n",
    "# → tensor([0.0, 0.5, 3.7, 5.0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "27e70333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# register hooks \n",
    "# The hook you attach with tensor.register_hook(hook_fn) is a gradient hook.\n",
    "# This is different from a module hook, which you attach to an nn.Module (like model.layer1.register_forward_hook(...)). Those can fire on the forward pass to inspect activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "f3378d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- HOOK FIRED ---\n",
      "Gradient Mean: -9.08e-03\n",
      "Gradient Std:  5.06e-02\n",
      "Gradient Norm: 3.60e-01\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 1. The Hook Function\n",
    "def print_grad_hook(grad):\n",
    "    \"\"\"\n",
    "    A simple hook function that prints the stats of a gradient tensor.\n",
    "    \"\"\"\n",
    "    if grad is not None:\n",
    "        print(f\"--- HOOK FIRED ---\")\n",
    "        print(f\"Gradient Mean: {grad.mean():.2e}\")\n",
    "        print(f\"Gradient Std:  {grad.std():.2e}\")\n",
    "        print(f\"Gradient Norm: {grad.norm():.2e}\")\n",
    "        print(f\"------------------\")\n",
    "    else:\n",
    "        print(\"--- HOOK FIRED (Grad is None) ---\")\n",
    "\n",
    "# --- Scenario Setup ---\n",
    "model = nn.Linear(10, 10)\n",
    "x = torch.randn(5, 10, requires_grad=True) # Input\n",
    "target = torch.randn(5, 10)               # Target\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# --- The Solution ---\n",
    "\n",
    "# 3. The Training Step (Forward Pass)\n",
    "y = model(x) # y is the tensor we want to inspect\n",
    "\n",
    "# 2. Attach the Hook\n",
    "# We attach the hook directly to the 'y' tensor.\n",
    "# It will fire when the gradient *for 'y'* is computed.\n",
    "y.register_hook(print_grad_hook)\n",
    "\n",
    "# 3. Trigger the Hook (Loss & Backward Pass)\n",
    "loss = criterion(y, target)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "id": "7435de13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collate function \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "id": "0c1e9c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "class ImbalancedTextDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        # 10 samples total\n",
    "        self.texts = [\n",
    "            torch.tensor([101, 4, 5, 102]),                 # class 0\n",
    "            torch.tensor([101, 6, 7, 8, 9, 10, 102]),       # class 0\n",
    "            torch.tensor([101, 11, 12, 102]),               # class 0\n",
    "            torch.tensor([101, 13, 14, 15, 16, 102]),       # class 0\n",
    "            torch.tensor([101, 17, 18, 19, 20, 21, 22, 102]), # class 0\n",
    "            torch.tensor([101, 23, 24, 102]),               # class 0\n",
    "            torch.tensor([101, 25, 26, 27, 28, 102]),       # class 0\n",
    "            torch.tensor([101, 29, 30, 102]),               # class 0\n",
    "            \n",
    "            torch.tensor([101, 100, 200, 300, 102]),       # class 1 (rare)\n",
    "            torch.tensor([101, 400, 500, 102]),           # class 1 (rare)\n",
    "        ]\n",
    "        self.labels = torch.tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 1])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts) \n",
    "    def __getitem__(self, index):\n",
    "        return (self.texts[index], self.labels[index])\n",
    "dataset = ImbalancedTextDataset()\n",
    "def pad_collate_fn(batch):\n",
    "    # batch , 2 \n",
    "    texts = [item[0] for item in batch]\n",
    "    labels =  [item[1] for item in batch]\n",
    "    padded_texts = pad_sequence(texts, batch_first=True, padding_value =0 )\n",
    "    labels = torch.stack(labels)\n",
    "    return padded_texts, labels\n",
    "labels = dataset.labels\n",
    "\n",
    "class_counts = torch.bincount(labels)\n",
    "class_weights = 1/class_counts\n",
    "sample_weights = class_weights[labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "id": "c387649b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = WeightedRandomSampler(\n",
    "    weights=sample_weights,\n",
    "    num_samples=len(sample_weights),\n",
    "    replacement=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "id": "caa4b3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD with momentum \n",
    "class momentumSGD:\n",
    "    def __init__(self,params, lr, momentum=0.9):\n",
    "        \n",
    "        self.lr = lr \n",
    "        self.momentum = momentum\n",
    "        self.params = list(params) \n",
    "        self.velocity_buffers = []\n",
    "        for param in self.params:\n",
    "            self.velocity_buffers.append(torch.zeros_like(param.data))\n",
    "        # veloctity buffers is no of layers x param shape \n",
    "    def step(self):\n",
    "        # update logic \n",
    "        with torch.no_grad():\n",
    "            for i  in range(len(self.params)):\n",
    "                param = self.params[i]\n",
    "                if param.grad is not None:\n",
    "                    gt = param.grad \n",
    "                    v_t_minus_1 = self.velocity_buffers[i]\n",
    "                    v_t = self.momentum*v_t_minus_1 + gt\n",
    "                    self.velocity_buffers[i] = v_t\n",
    "                    param.data -= self.lr*v_t\n",
    "        \n",
    "    def zero_grad(self, set_to_none = True):\n",
    "        for param in self.params:\n",
    "            if param.grad is not None:\n",
    "                if set_to_none:\n",
    "                    param.grad = None \n",
    "                else:\n",
    "                    param.grad.zero_()\n",
    "                \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "id": "5027f1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD with momentum \n",
    "class Adam:\n",
    "    def __init__(self,params, lr, beta1=0.9, beta2=0.99,eps=1e-6):\n",
    "        \n",
    "        self.lr = lr \n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.eps = eps\n",
    "        self.params = list(params) \n",
    "        self.momentum_buffer = []\n",
    "        self.second_moment_buffer = []\n",
    "        self.t = 0 \n",
    "        for param in self.params:\n",
    "            self.momentum_buffer.append(torch.zeros_like(param.data))\n",
    "            self.second_moment_buffer.append(torch.zeros_like(param.data))\n",
    "            \n",
    "        # veloctity buffers is no of layers x param shape \n",
    "    def step(self):\n",
    "        # update logic \n",
    "        self.t +=1\n",
    "        with torch.no_grad():\n",
    "            for i  in range(len(self.params)):\n",
    "                param = self.params[i]\n",
    "                if param.grad is not None:\n",
    "                    gt = param.grad \n",
    "                    mt_1 = self.momentum_buffer[i]\n",
    "                    vt_1 = self.second_moment_buffer[i]\n",
    "\n",
    "                    mt = self.beta1*mt_1 + (1-self.beta1)*gt\n",
    "                    vt = self.beta2*vt_1 + (1-self.beta2)*(gt**2)\n",
    "                    self.momentum_buffer[i] = mt \n",
    "                    self.second_moment_buffer[i] = vt \n",
    "                    mt = mt/(1-self.beta1**self.t)\n",
    "                    vt = vt/(1-self.beta2**self.t)\n",
    "                    \n",
    "                    param.data -= self.lr* mt /(vt**0.5+ self.eps)\n",
    "        \n",
    "    def zero_grad(self, set_to_none = True):\n",
    "        for param in self.params:\n",
    "            if param.grad is not None:\n",
    "                if set_to_none:\n",
    "                    param.grad = None \n",
    "                else:\n",
    "                    param.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "id": "265209fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 10, 64])"
      ]
     },
     "execution_count": 660,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# moe \n",
    "class MOE_Layer(nn.Module):\n",
    "    def __init__(self,d_model, dff, n_experts ):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model \n",
    "        self.dff = dff \n",
    "        self.n_experts = n_experts\n",
    "        self.gating_network = nn.Linear(d_model, n_experts)\n",
    "        self.experts = nn.ModuleList([nn.Sequential(\n",
    "            nn.Linear(d_model, dff), nn.ReLU(),\n",
    "            nn.Linear(dff,d_model)) for _ in range(n_experts)])\n",
    "    \n",
    "    def forward(self, X):\n",
    "        # X is the output from attention \n",
    "        # shape is N,seq_len , d_model\n",
    "        # this passes through the gating network \n",
    "        # output will be N, seq_len, E\n",
    "        gate_output = self.gating_network(X)\n",
    "        # select which experts to actiiivate \n",
    "        router_weights = nn.functional.softmax(gate_output, dim=-1) # N, seq_len\n",
    "        # N, seq_len\n",
    "        output = torch.zeros_like(X)\n",
    "        for i in range(self.n_experts):\n",
    "            \n",
    "            expert_output = self.experts[i](X) # N seq_len, d_model\n",
    "            w = router_weights[:, :, i] # N, seq_len\n",
    "            w = w.unsqueeze(-1)\n",
    "            output += w*expert_output\n",
    "            # N, seq_len  N seq_len d_model \n",
    "        return output \n",
    "X = torch.randn(100, 10, 64)\n",
    "moe_layer = MOE_Layer(64, 64*4, 4)\n",
    "out = moe_layer(X)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc304c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 10, 4])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer tensors of a single element can be converted to an index",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[664]\u001b[39m\u001b[32m, line 37\u001b[39m\n\u001b[32m     35\u001b[39m X = torch.randn(\u001b[32m100\u001b[39m, \u001b[32m10\u001b[39m, \u001b[32m64\u001b[39m)\n\u001b[32m     36\u001b[39m moe_layer = Topk_MOE_Layer(\u001b[32m64\u001b[39m, \u001b[32m64\u001b[39m*\u001b[32m4\u001b[39m, \u001b[32m4\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m out = \u001b[43mmoe_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m out.shape\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hoverboard_workspace/mine/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hoverboard_workspace/mine/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[664]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mTopk_MOE_Layer.forward\u001b[39m\u001b[34m(self, X, k)\u001b[39m\n\u001b[32m     27\u001b[39m output = torch.zeros_like(X)\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m top_k_indices:\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     expert_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexperts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m(X) \u001b[38;5;66;03m# N seq_len, d_model\u001b[39;00m\n\u001b[32m     30\u001b[39m     w = router_weights[:, :, i] \u001b[38;5;66;03m# N, seq_len\u001b[39;00m\n\u001b[32m     31\u001b[39m     w = w.unsqueeze(-\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hoverboard_workspace/mine/.conda/lib/python3.11/site-packages/torch/nn/modules/container.py:377\u001b[39m, in \u001b[36mModuleList.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m    375\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m._modules.values())[idx])\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._modules[\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_abs_string_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/hoverboard_workspace/mine/.conda/lib/python3.11/site-packages/torch/nn/modules/container.py:359\u001b[39m, in \u001b[36mModuleList._get_abs_string_index\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_abs_string_index\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[32m    358\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get the absolute index for the list of modules.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m     idx = operator.index(idx)\n\u001b[32m    360\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (-\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) <= idx < \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)):\n\u001b[32m    361\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mindex \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is out of range\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: only integer tensors of a single element can be converted to an index"
     ]
    }
   ],
   "source": [
    "# weighted sum MoE\n",
    "# sparse top k routing \n",
    "# instead of softmax use topk and choose only specific indices \n",
    "# moe \n",
    "class Topk_MOE_Layer(nn.Module):\n",
    "    def __init__(self,d_model, dff, n_experts ):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model \n",
    "        self.dff = dff \n",
    "        self.n_experts = n_experts\n",
    "        self.gating_network = nn.Linear(d_model, n_experts)\n",
    "        self.experts = nn.ModuleList([nn.Sequential(\n",
    "            nn.Linear(d_model, dff), nn.ReLU(),\n",
    "            nn.Linear(dff,d_model)) for _ in range(n_experts)])\n",
    "    \n",
    "    def forward(self, X, k ):\n",
    "        # X is the output from attention \n",
    "        # shape is N,seq_len , d_model\n",
    "        # this passes through the gating network \n",
    "        # output will be N, seq_len, E\n",
    "        gate_output = self.gating_network(X)\n",
    "        top_k_logits, top_k_indices = torch.topk(gate_output, dim = -1, k=k)\n",
    "        # N, seq_len k \n",
    "        print(top_k_logits.shape)\n",
    "        router_weights = F.softmax(top_k_logits, dim = -1)\n",
    "        # N, seq_len\n",
    "        output = torch.zeros_like(X)\n",
    "        all_expert_outputs = []\n",
    "        for expert in self.experts:\n",
    "            all_expert_outputs.append(expert(X))\n",
    "        all_expert_outputs = torch.stack(all_expert_outputs, dim =2)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        # for i in top_k_indices:\n",
    "        #     expert_output = self.experts[i](X) # N seq_len, d_model\n",
    "        #     w = router_weights[:, :, i] # N, seq_len\n",
    "        #     w = w.unsqueeze(-1)\n",
    "        #     output += w*expert_output\n",
    "        #     # N, seq_len  N seq_len d_model \n",
    "        # return output \n",
    "X = torch.randn(100, 10, 64)\n",
    "moe_layer = Topk_MOE_Layer(64, 64*4, 4)\n",
    "out = moe_layer(X, 4)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f383f50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
